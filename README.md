# FeedAI
FeedAI es una implementaci√≥n local de GPT que integra Ollama, OpenWebUI y Rancher. Permite crear un asistente para soporte con contexto personalizado a partir de archivos PDF, DOC, TXT y m√°s, usando el patr√≥n RAG. Su objetivo es ser una soluci√≥n simple y f√°cil de usar.



# üß† Instala tu propio ChatGPT local y gratis con Ollama + OpenWebUI

Este tutorial te ense√±a c√≥mo montar una versi√≥n local de ChatGPT usando [Ollama](https://ollama.com/) y [OpenWebUI](https://github.com/open-webui/open-webui). No necesitas conexi√≥n a Internet una vez instalado ni pagar suscripciones.

---

## ‚úÖ Requisitos

- Sistema operativo: Windows, macOS o Linux
- Conexi√≥n a Internet (solo para la instalaci√≥n)
- Rancher Desktop
- Terminal / consola

---

## 1. Instalar Ollama

Ollama permite ejecutar modelos LLM localmente.

### üîΩ Paso 1: Descargar Ollama

Ve a: [https://ollama.com/download](https://ollama.com/download)

Elige tu sistema operativo e instala.

### ‚ñ∂Ô∏è Paso 2: Ejecutar un modelo

Una vez instalado, abre la terminal y corre:

```bash
ollama run llama3
```

Esto descargar√° y ejecutar√° el modelo **LLaMA 3**, uno de los m√°s avanzados actualmente disponibles.

---

## 2. Instalar OpenWebUI

Es una interfaz tipo ChatGPT que se conecta con Ollama.

### üêÆ Paso 1: Descargar Rancher Desktop

Desde: [https://rancherdesktop.io/](https://rancherdesktop.io/)

Sigue el instalador para tu sistema operativo.

### ‚öôÔ∏è Paso 2: Configurar Rancher Desktop

- Aseg√∫rate de tener activado **containerd** o **dockerd** como backend.

---

### üöÄ Paso : Ejecutar OpenWebUI con Rancher

Corre el siguiente comando:

```bash
docker run -d -p 3000:8080 -v open-webui:/app/backend/data -e OLLAMA_API_BASE_URL=http://host.docker.internal:11434 --name open-webui   --restart always ghcr.io/open-webui/pen-webui:main
```

Esto levantar√° la interfaz en: [http://localhost:3000](http://localhost:3000)

---

## 3. Usar ChatGPT localmente

1. Abre tu navegador en `http://localhost:3000`
2. Aseg√∫rate de que Ollama est√© corriendo en segundo plano
3. Empieza a chatear con el modelo descargado

---

## ‚öôÔ∏è Consejos adicionales

- Puedes cambiar el modelo con: `ollama run mistral` o `ollama run gemma`
- Si tienes GPU, Ollama la usar√° autom√°ticamente
- OpenWebUI guarda tu historial y permite personalizar la experiencia

---

## üßº Para detener

```bash
docker stop openwebui
ollama stop llama3
```

---

## üìö Recursos

- Ollama Docs: https://ollama.com
- OpenWebUI GitHub: https://github.com/open-webui/open-webui

---

## üß≠ Seleccionar el contexto de Docker correcto para Rancher Desktop

Si est√°s usando Rancher Desktop, aseg√∫rate de que tu terminal est√© usando el contexto adecuado de Docker. Ejecuta:

```bash
docker context use rancher-desktop
```

Este comando garantiza que los contenedores se ejecuten en el entorno de Rancher y no en otro motor Docker que puedas tener instalado.

---
